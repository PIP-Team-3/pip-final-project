# P2N â€” CRITICAL FIX PLAN: Twoâ€‘Stage Planner Structured Outputs & Phaseâ€‘2 Verification
**Date:** 2025-10-10 00:41:26 UTC  
**Scope:** Fix Stageâ€‘2 planner failures, verify datasetâ€‘aware notebooks (Phase 2), keep twoâ€‘stage architecture stable.

---

## ğŸ” Executive Summary

- **Observed issue:** Twoâ€‘stage planner fails schema validation ~80â€“90% of the time; errors like _â€œInput should be a valid numberâ€_ indicate **numeric fields returned as strings**.
- **Root cause:** Stageâ€‘2 (gptâ€‘4o) currently emits **unstructured JSON**; the prompt asks to â€œmatch schemaâ€, but no hard schema is enforced.
- **Decision:** **Adopt Structured Outputs for Stageâ€‘2** (Responses API `response_format: json_schema`) and **keep the twoâ€‘stage approach**. Add small prompt guardrails as a beltâ€‘andâ€‘suspenders.
- **Status elsewhere:** Materialize MIME issue fixed; Phaseâ€‘2 dataset selection logic exists but has **not been validated live** yet.
- **Goal for this cycle:** Raise Stageâ€‘2 success rate to **â‰¥ 90%**, then prove Phaseâ€‘2 by generating & inspecting real notebooks that **load the right dataset** (not synthetic).

---

## âœ… Recommended Path (Options compared)

| Option | What it does | Pros | Cons | Decision |
|---|---|---|---|---|
| **A. Prompt hardening only** | Tell Stageâ€‘2 to emit numbers as JSON numbers | Quick | Still brittle; wonâ€™t prevent structural drift | **Use as backâ€‘up only** |
| **B. Structured Outputs** | Stageâ€‘2 uses **Responses API** `response_format=json_schema` with our **PlanDocumentV11** schema | Robust typing; fewer retries; deterministic | Slightly more wiring; must pass full schema | **PRIMARY** |
| **C. Oneâ€‘stage (gptâ€‘4o only)** | Disable o3â€‘mini; do analysis + JSON in one step | Less moving parts | Loses the highâ€‘quality reasoning of o3â€‘mini; cost/quality tradeoffs | **No** (keep twoâ€‘stage) |

**We will implement B (Structured Outputs) and retain A as textual guardrails in the prompt.**

---

## ğŸ§© Exact Implementation (no code changes applied here â€” use as a patch plan)

### 1) Stageâ€‘2: call **Responses API** with **Structured Outputs**

**Where:** `api/app/routers/plans.py` â€” Stageâ€‘2 â€œschema fixerâ€ block.

**Key changes:**  
- Use `client.responses.create(stream=False, â€¦)` with:
  - `response_format={"type": "json_schema", "json_schema": {"name": "plan_document", "schema": PlanDocumentV11.model_json_schema()}}`
  - `temperature=0` (allowed on gptâ€‘4o) to stabilize JSON
- **Do not stream Stageâ€‘2**; retrieve the **final JSON string**; parse and validate.

**Pseudoâ€‘diff (illustrative):**
```python
# before: streaming + freeform JSON parsing

# after (Stageâ€‘2 structured output, nonâ€‘stream):
schema = PlanDocumentV11.model_json_schema()
resp = client.responses.create(
    model=settings.openai_jsonizer_model,  # gpt-4o
    input=[
        { "type": "message", "role": "developer", "content": [{
            "type": "input_text",
            "text": STAGE2_DEV_INSTRUCTIONS  # see below
        }]},
        { "type": "message", "role": "user", "content": [{
            "type": "input_text",
            "text": stage1_output_text  # the o3-mini reasoning text or malformed JSON
        }]}        
    ],
    response_format={
        "type": "json_schema",
        "json_schema": {
            "name": "plan_document",
            "schema": schema,  # full Pydantic v2 JSON schema
            # Optional: "strict_schema": True  (if supported in your SDK build)
        },
    },
    temperature=0,
    max_output_tokens=4096,
)

# extract the single JSON doc from resp.output_text or resp.output[...]
json_text = resp.output_text  # (use the SDKâ€™s accessor you already standardized)
plan = PlanDocumentV11.model_validate_json(json_text)  # strict validation
```

### 2) Stageâ€‘2 prompt guardrails (beltâ€‘andâ€‘suspenders)

**Where:** the Stageâ€‘2 developer message (your â€œschema fixerâ€ prompt).

Add a block like:
```
CRITICAL JSON RULES:
- All numeric fields **must** be JSON numbers (not strings). Example: "epochs": 10 (âœ…), "epochs": "10" (âŒ)
- Use `null` for truly unknown optionals; avoid empty strings.
- Arrays must contain elements of the correct type (e.g., integers for kernel sizes).
- The output must be a **single JSON object** matching the provided JSON Schema **exactly**.
- Do not include any commentary outside the JSON.
```

Keep the rest of your Stageâ€‘2 guidance (mapping from free text â†’ schema) unchanged.

### 3) Stageâ€‘1 (o3â€‘mini) call hygiene

- Ensure **no unsupported params**: remove `temperature`, `top_p`, `presence_penalty`, `frequency_penalty`.
- Keep `max_output_tokens` high enough (e.g., **8192**) and **filter out `web_search_preview`** in tools.
- Continue to **stream** Stageâ€‘1 and **buffer deltas**; use buffered text if the completion event is flaky.

---

## ğŸ§ª Test Plan (raise Stageâ€‘2 success â‰¥ 90%)

### A. Unit / Contract tests (fast, no API)

1. **Schema snapshot test**  
   - Assert `PlanDocumentV11.model_json_schema()` contains numeric types for: `epochs`, `batch_size`, `learning_rate`, etc.
   - Rejects strings for numeric fields when `model_validate_json` runs under strict config.

2. **Type coercion negative test**  
   - Feed `"epochs": "10"` to `model_validate_json` and **expect failure** (guards remain strict).

3. **Generator smoke tests (no downloads)**  
   - Given `dataset.name="sst2"`, `GeneratorFactory.get_dataset_generator(plan)` â†’ `HuggingFaceDatasetGenerator`.  
   - Generated code contains `load_dataset("glue", "sst2")` and `cache_dir` handling.  
   - No `make_classification()` appears.

### B. Stageâ€‘2 live tests (API hitting OpenAI)

4. **Deterministic golden case**  
   - Construct a minimal Stageâ€‘1 output with intentionally stringâ€‘typed numbers (e.g., `"epochs": "10"`).  
   - Stageâ€‘2 must output the same fields as **JSON numbers**. Validate with Pydantic.

5. **Long reasoning case**  
   - Provide a ~2â€“4k token Stageâ€‘1 rationale including quotes/citations.  
   - Confirm Stageâ€‘2 produces valid JSON on first try â‰¥ 80% of runs; if not, retry once.

### C. Endâ€‘toâ€‘End plan â†’ notebook

6. **Planner endpoint full run**  
   - Input: claims (e.g., SSTâ€‘2 accuracy).  
   - Expect: `200 OK`, valid Plan JSON v1.1, DB persisted.

7. **Materialize**  
   - Generate notebook; **assert** code contains the correct dataset loader:  
     - For SSTâ€‘2: `load_dataset("glue", "sst2", cache_dir=...)`  
     - For Fashionâ€‘MNIST: `torchvision.datasets.FashionMNIST(..., download=...)`
   - Assert requirements include: `datasets` (HF) or `torchvision` (vision) as needed.

8. **Smoke execute (optional)**  
   - Run in sandbox with `OFFLINE_MODE=true` and a preâ€‘seeded cache directory to avoid downloads.  
   - Assert it produces `metrics.json` and logs `dataset_samples` metric.  

**Acceptance:** Stageâ€‘2 structured output success rate **â‰¥ 90%** on 10 consecutive runs; materialized notebooks load the right dataset (no synthetic).

---

## ğŸ“¦ Phaseâ€‘2 Verification Checklist (Datasets & Notebooks)

- [ ] Registry present with: `sst2`, `imdb`, `ag_news`, `trec`, `mnist`, `fashionmnist`, `cifar10` (+ aliases).  
- [ ] Factory routes to correct generator per dataset family (HF/torchvision/sklearn).  
- [ ] Notebook includes cache/offline env vars (`DATASET_CACHE_DIR`, `OFFLINE_MODE`, `MAX_TRAIN_SAMPLES`).  
- [ ] Requirements reflect the chosen generator (`datasets` or `torchvision` or pure sklearn).  
- [ ] No `make_classification()` if a known dataset is selected.  
- [ ] SSE emits `stage_update: dataset_load` before data prep.  

---

## ğŸ“š Paper Selection Policy (what to reproduce first)

To ensure reliable demos and fast runs under CPU limits, prioritize:

### Tier A â€” Fast & fully accessible
1. **Kim (2014) â€“ CNN for Sentence Classification** â€” focus on **SSTâ€‘2**, **TREC**, **IMDB**, **AG News**.  
   - Paper: https://arxiv.org/abs/1408.5882  
   - Datasets:  
     - GLUE **SSTâ€‘2**: https://huggingface.co/datasets/glue  
     - **TREC**: https://huggingface.co/datasets/trec  
     - **AG News**: https://huggingface.co/datasets/ag_news  
     - **IMDB**: https://huggingface.co/datasets/imdb  

2. **Fashionâ€‘MNIST** (Xiao et al., 2017) â€” torchvision loader.  
   - Paper: https://arxiv.org/abs/1708.07747

3. **IMDB** sentiment (Maas et al., 2011) â€” HF loader.  
   - Paper: https://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf

### Tier B â€” Common baselines (OK with subsampling)
4. **Charâ€‘CNNs** (Zhang et al., 2015) â€” start with **AG News**.  
   - Paper: https://arxiv.org/abs/1509.01626

5. **MNIST / CIFARâ€‘10** baselines â€” torchvision loaders.  
   - MNIST: http://yann.lecun.com/exdb/mnist/  
   - CIFARâ€‘10: https://www.cs.toronto.edu/~kriz/cifar.html  

### Tier C â€” Heavier / partial reproductions
6. **ResNet (2015)** â€” run on **CIFARâ€‘10** with ResNetâ€‘18/34 under CPU.  
   - Paper: https://arxiv.org/abs/1512.03385

7. **BERT (2018)** â€” **fineâ€‘tune** on SSTâ€‘2; no preâ€‘training.  
   - Paper: https://arxiv.org/abs/1810.04805

---

## âš™ï¸ Guardrails & Resilience

- **Stageâ€‘1 toolset:** o3â€‘mini **without** `web_search_preview`; keep File Search only.  
- **Stageâ€‘2 determinism:** `temperature=0` and structured output; reâ€‘try once on parse error.  
- **Strict validation stays on:** we want the model to conform, not the validator to coerce.  
- **Fallbacks:** if dataset unresolved â†’ synthetic generator; log a `WARN` and add the dataset to registry in a followâ€‘up PR.  

---

## ğŸ“ˆ Observability & Tuning

- Log Stageâ€‘2 payload keys: `response_format`, `model`, `max_output_tokens`, and the byte length of JSON.  
- Emit SSE `stage_update` milestones: `plan_stage2_start`, `plan_stage2_done`, and `schema_validate_pass|fail`.  
- Track rolling success rate (last 20 runs) and median latency for Stageâ€‘1 and Stageâ€‘2 separately.  

---

## ğŸ—ºï¸ Milestones & Acceptance

1) **M1 â€” Stageâ€‘2 Structured Outputs**  
   - Code switched to Responses API structured outputs (nonâ€‘stream).  
   - â‰¥ 90% success on 10 consecutive runs.  
   - Pydantic strict validation passes.  

2) **M2 â€” Phaseâ€‘2 Dataset Verification**  
   - Planner â†’ Materialize produces notebooks that load real datasets for **SSTâ€‘2**, **IMDB**, **Fashionâ€‘MNIST**.  
   - Requirements correctly reflect loaders.  
   - SSE shows `dataset_load` and `dataset_samples`.  

3) **M3 â€” Execution Dryâ€‘Run (optional)**  
   - Run notebooks in sandbox with `OFFLINE_MODE=true` and preâ€‘cached datasets.  
   - Capture `metrics.json` and logs.  

When M1 & M2 pass, Phaseâ€‘2 can be marked **complete**.

---

## ğŸ§° Rollback / Fallback Paths

- If structured outputs become unstable, **temporarily**:
  - Add preâ€‘validation sanitizer that converts known numeric fields from strings â†’ numbers.
  - As a last resort, run singleâ€‘stage gptâ€‘4o with `response_format=json_schema` (lower reasoning quality).

---

## ğŸ“‹ Action Items (sequenced)

1. Wire Stageâ€‘2 to Responses API **structured outputs** (nonâ€‘stream).  
2. Add prompt guardrails for numeric types & â€œJSON onlyâ€ output.  
3. Remove unsupported params from Stageâ€‘1 (o3â€‘mini); keep file_search only.  
4. Write unit + live tests above; run 10Ã— loop to confirm â‰¥ 90% pass.  
5. Validate notebooks for **SSTâ€‘2 / IMDB / Fashionâ€‘MNIST** (no synthetic).  
6. Document results; update status docs and roadmap.  

---

*Prepared for implementation; copy/paste diffs into your codebase. No runtime changes were made by this document.*
